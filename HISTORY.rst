=========
Changelog
=========

0.2.0 - 12.12.2024
------------------

- added `HISTORY.rst` to start a Changelog of the changes for each version of the program
- added `DEVELOP.rst` which contains information about the development environment of the 
  project (information about runnning the unit tests for example)
- Replaced the `tox.ini` with a `tox.toml` file
- Added the `ruff.toml` file to configure the Ruff Linter and code formatter
- Ported the `pyproject.toml` file from using poetry to using `uv` and `hatchling` as 
  the build backend.

1.0.0 - 01.05.2025
------------------

- First official release of the package

1.1.0 - 07.07.2025
------------------

- Added `AGENTS.md` file which contains information that can be used by AI agents such as 
  ChatGPT Codex to understand and work with the package
- Added the `manage.py` script which exposes an additional command line interface specifically 
  used for the management and maintance of the database.
  - `metadata` command group to interact with the local and remote version of the metadata.yml file 
  - `dataset` command group used to trigger the creation and upload of the local datasets.
- changes to the command line interface `cmdata`
  - `remote` command group to interact with the remote file share server
    - `upload` command to upload arbitrary files to the file share server
- Added new datasets.
  - `skin_irritation` binary classification dataset on skin irritation
  - `skin_sensitizers` binary classification dataset on skin sensitization
  - `elanos_bp` regression of boiling point
  - `elanos_vp` regression of vapor pressure 

1.1.1 - 07.07.2025
------------------

- Added `prettytable` as a dependency to create markdown tables in the documentation
- Changes to the `cli.py` CLI
  - `list` command now also printes the verbose name / short description of the datasets
- Changes to the `manage.py` CLI
  - Added the `docs` command group to manage the documentation
    - `collect-datasets` which collects all the datasets that are listed in the metadata.yml file and 
    creates a new markdown docs file in the docs folder with a table containing all those datasets.

1.1.2 - 01.09.2025
------------------

- Changed the default template for the `config.toml` file to include commented out example values for the 
  nextcloud remote file share configuration and to fix the default download location.

1.2.0 - 04.09.2025
------------------

General:

- Set the default SSL verification in the `web.py` module to `True` to avoid security issues when downloading files from 
  the internet.
- Added the `CLAUDE.md` file which contains information that can be used by AI agents such as 
  Claude to understand and work with the package

Command line interface:

- Added the `remote show` command which will display some useful information for the currently registered 
  file share location such as the URL and additional parameters such as the DAV username and password if they
  exist.
- Added the `remote diff` command which allows to compare the local version and the remote file share version 
  of the metadata.yml file and prints the difference to the console

Manage CLI:

- Added the `metadata diff` command which allows to compare the local version and the remote file share version 
  of the metadata.yml file and prints the difference to the console
  
Datasets:

- Added the `tadf` dataset associated with OLED design to the database


1.2.1 - 22.09.2025
------------------

- Modified the syntax of type annotations so that the package is now actually compatible with 
  Python Version up to 3.8 at the lower end and Python 3.12 at the upper end.

Testing

- Using `nox` now for the testing sessions instead of `tox` due to the much faster uv backend to 
  create the virtual environments.

1.3.0 - 12.09.2025
-------------------

Packaging

- Changed the minimum required version of pycomex to `0.23.0` to support the most recent features
  such as the caching system which has also been implemented now in the dataset processing scripts.

Command Line Interface

- Changed the logo which is displayed at the beginning of the help message to "CMDATA" in another
  ascii font and added a logo image in ANSI art.
- Fixed the formatting of the 

Datasets

- Added the `HOPV15_exp` dataset which contains experimental values for organic photovoltaic materials
  to the database.
- Added missing target descriptions for the QM9 dataset.
- Added the `melting_point` dataset which contains melting points for small organic molecules
  to the database.

1.4.0 - 06.10.2025
-------------------

Core Features

- Implemented **StreamingDataset** architecture for memory-efficient access to large molecular datasets
  - ``SmilesDataset``: Lazy-loading of SMILES strings from CSV files with minimal memory footprint
  - ``XyzDataset``: Lazy-loading of 3D molecular structures from XYZ file bundles, supporting multiple format parsers (default, qm9, hopv15)
  - ``GraphDataset``: On-the-fly conversion from raw molecular representations (SMILES or XYZ) to graph dicts
    - Automatic detection of dataset format (SMILES vs XYZ) for transparent handling
    - Sequential mode (num_workers=0) for optimal performance with typical molecules (~2000 mol/s)
    - Parallel mode (num_workers>0) with multi-process architecture for complex molecules or custom processing
    - Deadlock-free producer-collector-worker design that maintains dataset order while enabling true CPU parallelism
  - ``ShuffleDataset``: Approximate shuffling using fixed-size buffer for training with shuffled data while maintaining low memory usage

Documentation

- Added comprehensive streaming datasets documentation (``docs/api_streaming_datasets.md``) covering:
  - Motivation and use cases for streaming vs pre-processed datasets
  - Detailed usage examples for all streaming dataset classes
  - Performance considerations and when to use sequential vs parallel processing
  - Integration with deep learning frameworks and training workflows
  - Guidance on choosing between SMILES and XYZ formats
- Added Architecture Decision Record (``docs/architecture_decisions/004_streaming_datasets.md``) documenting:
  - Design rationale for streaming architecture
  - Detailed explanation of parallel processing implementation and deadlock prevention
  - Trade-offs between streaming and pre-processed datasets
  - Auto-detection mechanism for SMILES vs XYZ datasets

Testing

- Added comprehensive unit tests for streaming datasets:
  - ``tests/test_dataset.py``: Core functionality tests for SmilesDataset, XyzDataset, GraphDataset, and ShuffleDataset
  - ``tests/test_xyz_dataset.py``: XYZ-specific functionality and format parser tests
  - ``tests/test_xyz_bundle.py``: XYZ bundle file handling tests
  - ``tests/test_dataset_benchmark.py``: Performance benchmarks for sequential vs parallel processing modes
- Removed deprecated ``tests/test_datasets.py`` in favor of new dataset-specific test files
- Updated existing tests (``test_docs.py``, ``test_main.py``, ``test_web.py``) to accommodate streaming dataset functionality

